# ğŸ¤Ÿ DeepSign-TID â€” TÃ¼rk Ä°ÅŸaret Dili TanÄ±ma Sistemi
### Turkish Sign Language Recognition System

<p align="center">
  <img src="training_plot.png" alt="Training Results" width="700"/>
</p>

---

## ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e

### ğŸ“Œ Proje HakkÄ±nda

DeepSign-TID, gerÃ§ek zamanlÄ± **TÃ¼rk Ä°ÅŸaret Dili (TÄ°D)** tanÄ±ma sistemidir. Kamera gÃ¶rÃ¼ntÃ¼sÃ¼nden el ve vÃ¼cut hareketlerini algÄ±layarak 226 farklÄ± iÅŸareti tanÄ±yabilir ve cÃ¼mle oluÅŸturabilir.

### ğŸ† SonuÃ§lar

| Model | DoÄŸruluk | Top-3 | Epoch |
|-------|----------|-------|-------|
| MLP (Baseline) | %69.94 | %88.16 | 80 |
| **LSTM (Final)** | **%78.36** | **%91.40** | 60 |

- **226 sÄ±nÄ±f** Ã¼zerinde %78.36 doÄŸruluk
- **Top-3 %91.40** â†’ Neredeyse her zaman doÄŸru tahmin ilk 3'te
- Early stopping ile gereksiz eÄŸitim Ã¶nlendi

### ğŸ”§ Teknik Detaylar

**Model Mimarisi (SimpleLSTM):**
- 2 katmanlÄ± Ã§ift yÃ¶nlÃ¼ (bidirectional) LSTM
- Attention pooling (tÃ¼m zaman adÄ±mlarÄ±nda aÄŸÄ±rlÄ±klÄ± ortalama)
- LayerNorm + Dropout (0.5) ile gÃ¼Ã§lÃ¼ regularization
- ~2.8M parametre

**Veri Ä°ÅŸleme:**
- Veri seti: [AUTSL](https://cvml.ankara.edu.tr/datasets/) (226 sÄ±nÄ±f, ~35.000 video)
- MediaPipe Tasks API ile landmark Ã§Ä±karÄ±mÄ±
- Her frame: 258 Ã¶zellik (33 vÃ¼cut Ã— 4 + 21 sol el Ã— 3 + 21 saÄŸ el Ã— 3)
- Sekans uzunluÄŸu: 48 frame (~1.6 saniye)

**Web UygulamasÄ±:**
- Hareket tabanlÄ± iÅŸaret segmentasyonu (sÃ¼rekli tahmin yerine)
- GerÃ§ek zamanlÄ± landmark gÃ¶rselleÅŸtirme
- Flask + OpenCV + MediaPipe Tasks API

### ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# 1. Conda ortamÄ±nÄ± aktifle (GPU desteÄŸi iÃ§in)
conda activate base

# 2. Projeyi baÅŸlat
python run.py
# SeÃ§enek 4: Web Application

# 3. TarayÄ±cÄ±da aÃ§
# http://localhost:5000
```

### ğŸ“ Proje YapÄ±sÄ±

```
DeepSign-TID/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ server.py              # Flask web sunucusu
â”‚   â”œâ”€â”€ pytorch_predictor.py   # PyTorch + MediaPipe entegrasyonu
â”‚   â”œâ”€â”€ templates/             # HTML ÅŸablonlarÄ±
â”‚   â””â”€â”€ static/                # CSS/JS dosyalarÄ±
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocess.py      # MediaPipe landmark Ã§Ä±karÄ±mÄ±
â”‚   â”‚   â””â”€â”€ dataset.py         # PyTorch Dataset sÄ±nÄ±fÄ±
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ultra_simple.py    # MLP ve LSTM modelleri
â”‚   â”‚   â””â”€â”€ hybrid_model.py    # Hibrit model (GRU + CNN)
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ train.py           # EÄŸitim scripti
â”‚       â””â”€â”€ config.py          # Hiperparametreler
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pth         # EÄŸitilmiÅŸ LSTM modeli (%78.36)
â”œâ”€â”€ training_plot.png          # EÄŸitim grafiÄŸi
â”œâ”€â”€ run.py                     # Ana baÅŸlatÄ±cÄ±
â””â”€â”€ requirements.txt
```

### âš™ï¸ Gereksinimler

```bash
pip install -r requirements.txt
```

| Paket | Versiyon |
|-------|----------|
| Python | 3.13+ |
| PyTorch | 2.7.1+cu118 |
| MediaPipe | 0.10.31 |
| Flask | 3.x |
| OpenCV | 4.x |
| NumPy | 1.x |

### ğŸ¯ KullanÄ±m

1. Web uygulamasÄ±nÄ± baÅŸlat
2. Kameraya doÄŸru iÅŸaret yap
3. El hareketi algÄ±landÄ±ÄŸÄ±nda sistem otomatik kayÄ±t baÅŸlatÄ±r
4. Ä°ÅŸaret tamamlandÄ±ÄŸÄ±nda tahmin gÃ¶sterilir
5. Kelimeyi cÃ¼mleye ekle

---

## ğŸ‡¬ğŸ‡§ English

### ğŸ“Œ About

DeepSign-TID is a real-time **Turkish Sign Language (TÄ°D)** recognition system. It detects hand and body movements from a camera feed and can recognize 226 different signs to build sentences.

### ğŸ† Results

| Model | Accuracy | Top-3 | Epochs |
|-------|----------|-------|--------|
| MLP (Baseline) | 69.94% | 88.16% | 80 |
| **LSTM (Final)** | **78.36%** | **91.40%** | 60 |

- **78.36% accuracy** across 226 sign classes
- **91.40% Top-3** â†’ Correct sign almost always in top 3 predictions
- Early stopping prevented overfitting

### ğŸ”§ Technical Details

**Model Architecture (SimpleLSTM):**
- 2-layer bidirectional LSTM
- Attention pooling over all timesteps
- LayerNorm + Dropout (0.5) for strong regularization
- ~2.8M parameters

**Data Pipeline:**
- Dataset: [AUTSL](https://cvml.ankara.edu.tr/datasets/) (226 classes, ~35,000 videos)
- Landmark extraction via MediaPipe Tasks API
- Per frame: 258 features (33 pose Ã— 4 + 21 left hand Ã— 3 + 21 right hand Ã— 3)
- Sequence length: 48 frames (~1.6 seconds)

**Web Application:**
- Motion-based sign segmentation (predicts only on complete gestures)
- Real-time landmark visualization
- Flask + OpenCV + MediaPipe Tasks API

### ğŸš€ Quick Start

```bash
# 1. Activate conda environment (for GPU support)
conda activate base

# 2. Launch the app
python run.py
# Select option 4: Web Application

# 3. Open in browser
# http://localhost:5000
```

### âš™ï¸ Requirements

```bash
pip install -r requirements.txt
```

| Package | Version |
|---------|---------|
| Python | 3.13+ |
| PyTorch | 2.7.1+cu118 |
| MediaPipe | 0.10.31 |
| Flask | 3.x |
| OpenCV | 4.x |
| NumPy | 1.x |

### ğŸ¯ How to Use

1. Start the web application
2. Face the camera and perform a sign
3. System automatically starts recording when hand movement is detected
4. Prediction is shown when the sign is complete
5. Add the word to your sentence

### ğŸ“Š Training Your Own Model

```bash
# Train LSTM model from scratch
python src/training/train.py --model lstm --epochs 100

# Resume from checkpoint
python src/training/train.py --model lstm --epochs 50 --resume models/best_model.pth
```

---

## ğŸ“œ License / Lisans

MIT License

## ğŸ™ Acknowledgements / TeÅŸekkÃ¼rler

- [AUTSL Dataset](https://cvml.ankara.edu.tr/datasets/) â€” Ankara Ãœniversitesi
- [MediaPipe](https://mediapipe.dev/) â€” Google
